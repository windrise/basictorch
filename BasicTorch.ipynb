{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BasicTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nwh79kFTHyaV",
        "jQsxxmgyTI_z",
        "sb_p4uHzTMnQ",
        "M_ewHLmoT7nX",
        "Pqgpp-KLQEQK"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windrise/basictorch/blob/master/BasicTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkp8w3rpGsyU",
        "colab_type": "text"
      },
      "source": [
        "# 基本环境测试\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7A0lCuHGCrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5DJdrRoGKSJ",
        "colab_type": "code",
        "outputId": "355d1328-16e5-4dc1-bcb1-c2e66503c7e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        " x = torch.Tensor(5,3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 2.2169e-35  0.0000e+00  4.4842e-44\n",
            " 0.0000e+00         nan  0.0000e+00\n",
            " 6.7947e+22  2.6079e+20  6.6383e-07\n",
            " 1.0514e-05  8.5455e-07  4.1536e-08\n",
            " 2.1253e-07  8.5013e-07  0.0000e+00\n",
            "[torch.FloatTensor of size 5x3]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFK1w0UaG6se",
        "colab_type": "code",
        "outputId": "3a5a84d5-6f28-489e-9ae6-11580c3ff345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "y = torch.rand(5,3)\n",
        "print(y)\n",
        "print(y.size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 0.6284  0.5950  0.2834\n",
            " 0.2547  0.9488  0.1956\n",
            " 0.2709  0.5084  0.3546\n",
            " 0.7146  0.9547  0.8258\n",
            " 0.6737  0.4501  0.6427\n",
            "[torch.FloatTensor of size 5x3]\n",
            "\n",
            "<built-in method size of torch.FloatTensor object at 0x7f1e33021708>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y2e7JzIDK_U",
        "colab_type": "text"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g73-i1YQcuXU",
        "colab_type": "code",
        "outputId": "8da4c036-91eb-4be9-cb80-f6cc37d328a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OWJ0tJpdfcW",
        "colab_type": "code",
        "outputId": "523294e7-aa3e-4433-f54f-2e5f6b69fbd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jan  3 06:07:38 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AruI1MTVdlMu",
        "colab_type": "code",
        "outputId": "9f1d7d7a-5c6b-4c6c-9b46-930a4c77c679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S41Q45E4WIU2",
        "colab_type": "code",
        "outputId": "34895bc0-4d41-4310-d468-38237ef0619d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!python -V"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUCEL-l6DRNc",
        "colab_type": "text"
      },
      "source": [
        "## 操作系统信息"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZePGSh8-PEkt",
        "colab_type": "code",
        "outputId": "fd8e2317-667f-4dfd-e4f4-d9ad71d48262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!sudo lsb_release -a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.3 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTSRhRY_D354",
        "colab_type": "text"
      },
      "source": [
        "## 查看cuda版本"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W_9NsBGRCey",
        "colab_type": "code",
        "outputId": "13eca348-85e2-438a-f7c5-3f9a4060cbb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!cat /usr/local/cuda/version.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Version 10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXefBqyjPNXm",
        "colab_type": "code",
        "outputId": "c89150d2-0891-441a-ef76-025b6611dbb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvFbDg5RIvs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPUxw009HrRK",
        "colab_type": "text"
      },
      "source": [
        "## python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwh79kFTHyaV",
        "colab_type": "text"
      },
      "source": [
        "### 变量与对象\n",
        "对象：内存中存储数据的实体，有明确的类型。一切皆是对象，函数也是对象。  \n",
        "变量：指向对象的指针，对对象的引用。变量没有类型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO-nGk0jLtiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOFdk67THufV",
        "colab_type": "code",
        "outputId": "54265f7c-3841-4cbe-84c0-502d59fc19e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# 深浅拷贝\n",
        "'''\n",
        "拷贝：原则上就是把数据分离出来，复制其数据，并以后修改互不影响。\n",
        "先看一个非拷贝的例子\n",
        "=赋值：数据完全共享（=赋值是在内存中指向同一个对象，如果是可变(mutable)类型，比如列表，修改其中一个，另一个必定改变\n",
        "如果是不可变类型(immutable),比如字符串，修改了其中一个，另一个并不会变）\n",
        "'''\n",
        "import copy\n",
        "a = [1, 2, [1,2]]\n",
        "# 直接复制前后没有隔离   共享内存  地址相同\n",
        "b = a\n",
        "# 浅拷贝  数据半共享   只成功拷贝第一层\n",
        "c = copy.copy(a)\n",
        "d = a[:]\n",
        "# 深拷贝  前后两个变量完全隔离  数据完全不共享\n",
        "e = copy.deepcopy(a)\n",
        "a.append(3)\n",
        "a[2].append(3)\n",
        "a,b,c,d,e"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 2, [1, 2, 3], 3],\n",
              " [1, 2, [1, 2, 3], 3],\n",
              " [1, 2, [1, 2, 3]],\n",
              " [1, 2, [1, 2, 3]],\n",
              " [1, 2, [1, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQsxxmgyTI_z",
        "colab_type": "text"
      },
      "source": [
        "### 作用域"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb_p4uHzTMnQ",
        "colab_type": "text"
      },
      "source": [
        "### 高阶函数\n",
        "高阶函数指的是 接受函数作为输入或输出的函数。  \n",
        "对于python而言，函数是一等对象，既可以赋值给变量、添加到集合中、传参到函数中，也可以作为函数的返回值。  \n",
        "变量即为对对象的引用。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ewHLmoT7nX",
        "colab_type": "text"
      },
      "source": [
        "### **迭代器和生成器**\n",
        "> iter(),next(),yield  \n",
        "> list,dict,set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBnP1bSbNo0j",
        "colab_type": "text"
      },
      "source": [
        "## 常用工具  \n",
        "> 版本管理git&github\n",
        "> python调试器： pdb\n",
        "> 网页可视化： jupyter\n",
        "> 分屏工具： Terminator\n",
        "> 任务托管： Screen \n",
        "> 任务后台执行： &nohup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNePV9wrP8Ac",
        "colab_type": "text"
      },
      "source": [
        "## Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqgpp-KLQEQK",
        "colab_type": "text"
      },
      "source": [
        "### 数据类型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajxoXrPdNoh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ2UuQSyISuS",
        "colab_type": "code",
        "outputId": "493c9c2b-26e9-4a2d-8371-c3c9ebc5bf8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 创建新的Tensor, 默认是torch.FloatTensor类型\n",
        "a = torch.Tensor(2,2)\n",
        "a \n",
        "#a.type()  #'torch.FloatTensor'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.7791e-36, 0.0000e+00],\n",
              "        [4.4842e-44, 0.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAV6nDRJRVK9",
        "colab_type": "code",
        "outputId": "65b14d9a-85eb-43f5-984a-67cbce6b0489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 使用int()，float()，double()等直接进行数据类型的转换\n",
        "b = a.double()\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.7791e-36, 0.0000e+00],\n",
              "        [4.4842e-44, 0.0000e+00]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Ut0KgGRVcG",
        "colab_type": "code",
        "outputId": "d08feb70-c116-4ab6-c444-20a20bcc4627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 使用type()函数\n",
        "c = a.type(torch.DoubleTensor)\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.7791e-36, 0.0000e+00],\n",
              "        [4.4842e-44, 0.0000e+00]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcCZp_aPRZgo",
        "colab_type": "code",
        "outputId": "b3ef3753-aaaf-4077-9c89-5a22de882524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 使用type_as()函数\n",
        "d = a.type_as(b)\n",
        "d"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.7791e-36, 0.0000e+00],\n",
              "        [4.4842e-44, 0.0000e+00]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_cgOlcxUsBW",
        "colab_type": "text"
      },
      "source": [
        "### Tensor的创建和维度查看"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmrRWjnlUyOU",
        "colab_type": "text"
      },
      "source": [
        "* 基础Tensor函数 torch.Tensor(2,2) #(2,2)每一维大小 \n",
        "* 指定类型 torch.DoubleTensor(2,2)  \n",
        "* 使用Python的list序列 torch.Tensor([[1,2],[3,4]]) \n",
        "* 默认值为0 torch.zeros(2,2)\n",
        "* 默认值为1 torch.ones(2,2)\n",
        "* 对角张量 torch.eye(2,2)\n",
        "* 随机张量 torch.randn(2,2)\n",
        "* 随机排列张量 torch.randperm(4）\n",
        "\n",
        "> torch.arange(start,end,step)函数，从start到end,间距为step,一维向量\n",
        "> torch.linspace(start,end,steps)函数，从start到end,一共steps份，一维向量  \n",
        "> torch.randperm(num)生成长度为num的随机排列向量  \n",
        "> pytorch 0.4中增加了torch.tensor()方法，参数可以为Python的list，Numpy的ndarray等"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv-bsRxNSq5v",
        "colab_type": "code",
        "outputId": "873c227f-42ff-4e39-90c3-abfa891cfdd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "f = torch.eye(2,3)\n",
        "f"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMCC_vZhXy_4",
        "colab_type": "text"
      },
      "source": [
        "查看Tensor的维度\n",
        "> Tensor.shape或者size()函数可以查看 Tensor每一维大小  \n",
        "查看Tensor的元素总个数\n",
        "> Tensor.numel()或者Tensor.nelement()函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFZfv2DuYb2W",
        "colab_type": "text"
      },
      "source": [
        "### Tensor的组合与分块 \n",
        "组合： torch.cat(),torch.stack()  \n",
        "指沿着已有的数据的某一维度进行拼接，其他维度保持一致  \n",
        "分块： torch.chunk(),torch.split()  \n",
        "指将Tensor分割成不同的子Tensor，前者需要指定分块的数量，后者需要指定每一个分块的大小"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG38vcYbS3IY",
        "colab_type": "code",
        "outputId": "13120835-8e54-42ca-ae9c-18bd817d66fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "a = torch.Tensor([[1,2],[3,4]])\n",
        "b = torch.Tensor([[5,6],[7,8]])\n",
        "a,b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2.],\n",
              "         [3., 4.]]), tensor([[5., 6.],\n",
              "         [7., 8.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXIhnWCQcLvc",
        "colab_type": "code",
        "outputId": "2ae86229-41d9-4de4-b38d-ac7d46a7d92f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#以第一维进行拼接，则变成 4x2\n",
        "torch.cat([a,b],0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.],\n",
              "        [5., 6.],\n",
              "        [7., 8.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUfmdHiWcdrZ",
        "colab_type": "code",
        "outputId": "11507246-0323-4316-a7fe-ad350702df0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#以第一维进行拼接，则变成 2x4\n",
        "torch.cat([a,b],1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 5., 6.],\n",
              "        [3., 4., 7., 8.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALJRgzeWcsSr",
        "colab_type": "code",
        "outputId": "76afb423-b8ff-452a-a79a-516e8f8a7ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#以第0维进行stack,叠加的基本单位为序列本身，即为a和b，因此输出[a,b]， 输出维度为 2x2x2\n",
        "torch.stack([a,b],0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2.],\n",
              "         [3., 4.]],\n",
              "\n",
              "        [[5., 6.],\n",
              "         [7., 8.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6f8fbDqdH7P",
        "colab_type": "code",
        "outputId": "d6f73d28-15f7-4a53-f66f-5189d566dd0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#以第1维进行stack,叠加的基本单位为每一行， 输出维度为 2x2x2\n",
        "torch.stack([a,b],1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2.],\n",
              "         [5., 6.]],\n",
              "\n",
              "        [[3., 4.],\n",
              "         [7., 8.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_bg-dkndVrH",
        "colab_type": "code",
        "outputId": "a2b76234-17e9-4141-ae9c-28402f04b901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#以第2维进行stack,叠加的基本单位为每一行的每一个元素，输出维度为 2x2x2\n",
        "torch.stack([a,b],2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 5.],\n",
              "         [2., 6.]],\n",
              "\n",
              "        [[3., 7.],\n",
              "         [4., 8.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylTeCl72dsy_",
        "colab_type": "code",
        "outputId": "a178b493-a86f-4f89-8e4e-ab6bfbfe5bfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "a = torch.Tensor([[1,2,3],[4,5,6]])\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNJXwNYCeTKV",
        "colab_type": "code",
        "outputId": "d72a2365-95a1-432c-c472-88d54a8a1c83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 使用chunk,沿着第0维分块，一共分两块， 分成两个1x3的Tensor\n",
        "torch.chunk(a,2,0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3.]]), tensor([[4., 5., 6.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_4U8MtzfC_A",
        "colab_type": "code",
        "outputId": "6a8c5e2e-5c12-483b-c3fa-8d538c2c6ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 使用chunk,沿着第1维分块，一共分两块，不能整除是最后一个维数会小于前面的， 分成一个2x2和2x1的Tensor\n",
        "torch.chunk(a,2,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2.],\n",
              "         [4., 5.]]), tensor([[3.],\n",
              "         [6.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZMdf2vKfhfn",
        "colab_type": "code",
        "outputId": "690e9107-4fe3-4811-aaca-ac1dac890ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 使用split,沿着第0维分块，每一块维度是2，由于第一维维度书总共为2，因此相当于没有分割\n",
        "torch.split(a,2,0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3.],\n",
              "         [4., 5., 6.]]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS-Pz-K7f3C9",
        "colab_type": "code",
        "outputId": "fc2f5969-ba32-430e-9a70-771950223eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 使用split,沿着第1维分块，每一块维度是2，分成2x2，2x1\n",
        "torch.split(a,2,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2.],\n",
              "         [4., 5.]]), tensor([[3.],\n",
              "         [6.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH8_9rq5gDWa",
        "colab_type": "code",
        "outputId": "51656006-e512-4ec9-922c-9d0e9d12fc42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# split 也可以根据输入的list进行自动分块，list中的元素代表了每一个分块的维度\n",
        "torch.split(a,[1,2],1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [4.]]), tensor([[2., 3.],\n",
              "         [5., 6.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1SHEqC6gaJh",
        "colab_type": "text"
      },
      "source": [
        "### Tensor的索引和变形  \n",
        "与numpy类似，主要包含下标索引，表达式索引，使用torch.where()和Tensor.clamp()的选择性索引"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-RtAHxZgSeF",
        "colab_type": "code",
        "outputId": "782c8469-7a67-4193-c843-5dbc05498421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import torch\n",
        "a = torch.Tensor([[0,1],[2,3]])\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [2., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVvaZeJ2iDAv",
        "colab_type": "code",
        "outputId": "31b40cae-810c-42d9-8974-2f1f0d8adde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#根据下标索引\n",
        "a[1],a[0,1]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 3.]), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHVxvPbEiDq8",
        "colab_type": "code",
        "outputId": "c321170c-47c4-408f-f9e0-de42ec81d89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#选择a中大于0 的元素，返回和a相同大小的Tensor，符合条件的置为1，否则置为0；  a>0\n",
        "#选择符合条件的元素并返回，等价于torch.masked_select(a,a>0)  a[a>0]\n",
        "a>0,a[a>0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[False,  True],\n",
              "         [ True,  True]]), tensor([1., 2., 3.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh3My_4CLQD2",
        "colab_type": "code",
        "outputId": "7cdc4d57-8045-4faa-bc2a-3563108c9f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#选择非零元素的坐标，并返回\n",
        "torch.nonzero(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 0],\n",
              "        [1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4ym4xPvLj6o",
        "colab_type": "code",
        "outputId": "2ada0e53-8a72-45a1-e6fa-9813453a1411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#torch.where(condition,x,y), 满足condition的位置输出x，否则输出y\n",
        "torch.where(a>1,torch.full_like(a,1),a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WajykJoXL9Xv",
        "colab_type": "code",
        "outputId": "1d5deefb-a3e0-4174-9a35-707f7c191657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#对于Tensor元素进行限制可以使用clamp()函数，示例如下，限制最小值为1，最大值为2\n",
        "a.clamp(1,2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [2., 2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpOm-8pJMt0x",
        "colab_type": "text"
      },
      "source": [
        "Pytorch常用的变形操作\n",
        "\n",
        "---\n",
        "\n",
        "| 变形操作 | 功能  |  \n",
        "| :------:  | :------: |\n",
        "| view(),resize(),reshape() | 调整Tensor的形状，元素总数相同 |\n",
        "| transpose(),permute()   | 各维度之间的变换 |\n",
        "| squeeze(),unsqueeze()   | 处理size为1的维度 |\n",
        "| expand(),expand_as()   |  复制元素来扩展维度 |  \n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhqEWYmSYM3W",
        "colab_type": "text"
      },
      "source": [
        "#### 1.view()、resize()、reshape()函数  \n",
        "view(),resize(),reshape()函数可以在不改变Tensor数据的前提下任意改变Tensor的形状，必须保证调整前后元素总数相同，并且调整前后共享内存，三者的作用基本相同。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfiuA-DlMS_d",
        "colab_type": "code",
        "outputId": "7d6fb3a3-82e0-4547-cd9f-1a4c56ef0fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import torch\n",
        "a = torch.arange(1,5)\n",
        "b = a.view(2,2)\n",
        "b"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rboVW0RlgoM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4963e59a-5d4d-4dd9-956f-629bc677871d"
      },
      "source": [
        "c = a.reshape(4,1)\n",
        "c"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [2],\n",
              "        [3],\n",
              "        [4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rPirtMGhN67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "c18ee140-2cf3-4265-8f41-3b8644e59a45"
      },
      "source": [
        "d = a.resize(4,1)\n",
        "a,d"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:330: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4]), tensor([[1],\n",
              "         [2],\n",
              "         [3],\n",
              "         [4]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BSVDzOchOGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4f5a528-eda5-4f7d-e4b7-25bd9de6faaa"
      },
      "source": [
        "#改变b,c,d,则a也跟着改变\n",
        "b[0,0]=0\n",
        "c[1,0]=0\n",
        "d[2,0]=0\n",
        "a"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCxht519i1h9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "937b3fb4-e329-4de1-bd1e-b0a8b9472141"
      },
      "source": [
        "#如果想要直接改变Tensor的尺寸，可以使用resize_()的原地操作函数。在resize_()函数中，如果超出了原Tensor的大小，则重新分配新的内存，\n",
        "#如果小于原Tensor的大小，则剩余部分隐藏的保留\n",
        "c = a.resize_(2,3)\n",
        "c,a"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[                  0,                   0,                   0],\n",
              "         [                  4, 8746397786380201545, 7312272888175158610]]),\n",
              " tensor([[                  0,                   0,                   0],\n",
              "         [                  4, 8746397786380201545, 7312272888175158610]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBIU5Q4blAqw",
        "colab_type": "text"
      },
      "source": [
        "#### 2、transpose()和permute()函数\n",
        "transpose()函数可以将指定的两个维度的元素进行转置，  \n",
        "而permute()函数则可以按照给定的维度进行维度变换。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSSR4nM1mQmd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "cb32b233-fbee-41f7-b666-cae812fb64fe"
      },
      "source": [
        "a = torch.randn(2,2,2)\n",
        "a"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4759,  1.1461],\n",
              "         [-0.1048, -0.3149]],\n",
              "\n",
              "        [[ 0.2218,  1.1860],\n",
              "         [ 0.7640,  2.3186]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm1297C4mShm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#将第0维和第1维的元素进行转置\n",
        "a.transpose(0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b8SjtvRmlxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ca4ade9d-962d-4e6f-8af6-5b21b1beff3e"
      },
      "source": [
        "#按照第2,1,0 的顺序重新进行元素排列\n",
        "a[1,0,0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2218)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxwQXbg_mQxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = a.permute(2,1,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7cIZa5kn41c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dfd023aa-33f4-4491-c0ff-144101fdccaf"
      },
      "source": [
        "b[0,0,1]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2218)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qBtGSVrol1O",
        "colab_type": "text"
      },
      "source": [
        "#### 3、squeeze()和unsqueeze()函数  \n",
        "两者传入的参数都表示要处理的tensor的维度。  \n",
        "前者用于去除size为1的维度，也即--降维，而后者则是将指定的维度的size变为1，也即--升维，其中的参数是指定增加维度的位置."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IURq6RJCpD9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a8460747-aa53-4a9f-a297-81398f649c7a"
      },
      "source": [
        "a = torch.arange(0,6)\n",
        "b = a.view(2,3)\n",
        "b"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGNB1RtnqbiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "737546e1-316a-433d-b351-37135d0bd31e"
      },
      "source": [
        "#在第二维增加一个维度，使其维度变为（2,1,3） \n",
        "b.unsqueeze(1).shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfDmp3tSpFSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02077518-9fab-4628-9839-87320b574297"
      },
      "source": [
        "#先得到一个维度为（1,2,3）的tensor\n",
        "c = b.unsqueeze(0)\n",
        "c.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH1kawxCqKRo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bcb99ea9-88c4-406c-bda9-1aea7d9c9f9f"
      },
      "source": [
        "#使用squeeze()函数将第一维去掉\n",
        "c.squeeze(-3),c.squeeze(-3).shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0, 1, 2],\n",
              "         [3, 4, 5]]), torch.Size([2, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj3EEuzez35W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ccc2fee3-fcb5-4cbb-b321-acc1b223be18"
      },
      "source": [
        "#可以看出维度并没有变化，仍然为（1，2，3），这是因为只有维度为1时才会起作用\n",
        "c.squeeze(-2).shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAHQKyNN0Cuq",
        "colab_type": "text"
      },
      "source": [
        "#### 4、expand()和expand_as()函数\n",
        "有时候需要采用复制元素的形式来扩展Tensor的维度，这时expand就派上了用场。expand()函数将size=1的维度复制扩展为指定大小，也可以使用expand_as()函数指定为是特定Tensor的维度。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11RaRC9Sdv9C",
        "colab_type": "text"
      },
      "source": [
        "### Tensor的内存共享\n",
        "* 通过Tensor初始化Tensor：  \n",
        "通过Tensor初始化另一个Tensor或者通过Tensor的组合，分块，索引，变形操作来初始化另一个Tensor，则这两个Tensor共享内存\n",
        "* 原地操作符：  \n",
        "pytorch对于一些操作通过加后缀'\\_'实现了原地操作，如add\\_()和resize_()操作,即本身的Tensor会改变\n",
        "* Tensor和Numpy转换：  \n",
        "Tensor和Numpy可以高效的进行转换，并且转换前后的变量共享内存。甚至可以曲线救国。。。。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqPl7Bxu09js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTpBP0NUfEOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "759ca244-c019-41bb-b9e0-8a7e8407c50b"
      },
      "source": [
        "#原地操作符\n",
        "a = torch.Tensor([[1,2],[3,4]])\n",
        "b = a.add_(a)\n",
        "a"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 4.],\n",
              "        [6., 8.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulg6O0onfX8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02500b6c-a131-421c-ee0d-027e93a11411"
      },
      "source": [
        "#曲线就救国\n",
        "a = torch.randn(1,2)\n",
        "a "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3152, 0.4635]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Miv-nU7fjS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e03f24ad-7af7-4f68-fdff-eff27061f1ef"
      },
      "source": [
        "#将Tensor转换为numpy\n",
        "b = a.numpy()\n",
        "b"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.31517386, 0.46351725]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j96qL1LfjdC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a57ddb59-0734-4e25-f3d0-678e5dc1ebd9"
      },
      "source": [
        "#将numpy转换为Tensor\n",
        "c = torch.from_numpy(b)\n",
        "#Tensor转化为list\n",
        "d = a.tolist()\n",
        "c,d"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.3152, 0.4635]]), [[0.315173864364624, 0.4635172486305237]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu53NIJ8qTmC",
        "colab_type": "text"
      },
      "source": [
        "## Autograd与计算图\n",
        "pytorch 0.4版本将Tensor与Variable进行了整合"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc1e7-RvZv8K",
        "colab_type": "text"
      },
      "source": [
        "> 通过requires_grad参数创建支持自动求导的Tensor  \n",
        "> 默认为false，设置为True则需要求导。\n",
        "\n",
        "**Tensor有两种重要属性，分别记录了该Tensor的梯度和经历的操作**\n",
        "* grad： 该Tensor对应的梯度，类型为Tensor，并且与Tensor同维度。\n",
        "* grad_fn: 指向function对象，即该Tensor经过了什么样的操作，用作反向传播的梯度计算，如果该Tensor由用户创建，则该grad_fn为None"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt_L2y1QrOnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba0342e6-eef5-4006-e7ec-164a20a4abdc"
      },
      "source": [
        "import torch\n",
        "a = torch.randn(2,2,requires_grad=True)\n",
        "b = torch.randn(2,2)\n",
        "a.requires_grad,b.requires_grad"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD6ETyBaavbH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "731297c7-ebc8-4387-fac8-fcd74f4b2200"
      },
      "source": [
        "#也可以通过内置函数 requires_grad_()将Tensor变为需要求导\n",
        "b.requires_grad_()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0782,  1.2187],\n",
              "        [ 0.1011, -0.9570]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1dePFIpbDuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41eee12d-8611-42c6-ce03-22d340073f9e"
      },
      "source": [
        "#通过计算生产的Tensor，由于依赖的Tensor需要求导，因此c也需要求导\n",
        "c = a + b\n",
        "c.requires_grad"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRu0octebWaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ebbf540-f911-430d-a5fd-02e2fbe76f72"
      },
      "source": [
        "# a与b是自己创建的， grad_fn是None,而c的是一个Add函数创建的\n",
        "a.grad_fn,b.grad_fn,c.grad_fn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, <AddBackward0 at 0x7f8302fd1278>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42RTSPP0dcKM",
        "colab_type": "text"
      },
      "source": [
        "PyTorch0.4中，.data 仍保留，但建议使用 .detach(), 区别在于 .data 返回和 x 的相同数据 tensor, 但不会加入到x的计算历史里，且require s_grad = False, 这样有些时候是不安全的, 因为 x.data 不能被 autograd 追踪求微分 。 .detach() 返回相同数据的 tensor ,且 requires_grad=False ,但能通过 in-place 操作报告给 autograd 在进行反向传播的时候.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmuw3an2bws0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42d8f6cc-5004-43ad-9685-b15cafa2ebe0"
      },
      "source": [
        "#注意： 早些版本使用.data属性来获取数据，Pytorch0.4建议使用Tensor.detach()函数，因为.data属性在某型情况下不安全，原因在于对\n",
        "#.data生成的数据进行修改不会被 autograd追踪。Tensor.detach()函数生成的数据默认requires.grad 为false\n",
        "d = c.detach()\n",
        "d.requires_grad"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npLppnGFm66H",
        "colab_type": "text"
      },
      "source": [
        "### Autograd注意事项：\n",
        "动态图特性：  练习中自己感受  \n",
        "backward()函数还有一个需要传入的参数 grad_variabels,其代表了根节点的导数，也可以看作根节点各部分的权重系。因为Pytorch不支持Tensor对Tensor求导，求导是都是标量对于Tensor进行求导，因此如果根节点是向量，则应配以对应大小的权重，并求和得到标量，再反传。如果根节点的值是标量则参数可以省略，默认为1.  \n",
        "当有多个输出需要同时进行梯度反传时，需要将retain_graph设置为True，从而保证在计算多个输出的梯度时互不影响。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "879eDYRgokkk",
        "colab_type": "text"
      },
      "source": [
        "## 神经网络工具箱 `torch.nn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bcv5EZyqxHL",
        "colab_type": "text"
      },
      "source": [
        "`nn.Module`是pytorch提供的神经网络类，如果想实现某个神经网络，只需集成nn.Module，在初始化中定义模型结构和参数，在函数forward()中编写神经网络前向过程即可。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBh1q4kYb46O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 下面以一个由两个全连接成组成的感知机为例，介绍如何使用`nn.Module`构造模块化的神经网络。新建一个perception.py文件"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}